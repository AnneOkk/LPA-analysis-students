---
title: "R_code"
author: "Anne"
date: "8/20/2020"
output: html_document
---

# Preselection 

```{r loading_packs, eval = T, include = F, echo = F}
knitr::opts_chunk$set(include = T, echo = T, warning = F, message = F)
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("mediation", "foreign", "tidyverse","stargazer","multicon", "ggplot2", "plyr", "reshape2", "readxl", 
              "scales", "grid", "tidyLPA", "Rcpp", "naniar", "dplyr", "car", "mice", 
              "rstudioapi", "labelled", "modi", "semPlot", "kulife", "poLCA")
ipak(packages)
```

```{r}
 #library(rstudioapi)
# set_wd <- function() {
# current_path <- getActiveDocumentContext()$path 
#  setwd(dirname(current_path ))
#  print( getwd() )
 # }
# set_wd()
```

```{r}

options(knitr.table.format = function() {
  if (knitr::is_latex_output()) 'latex' else 'pandoc'
})

library(rlang)
library(tidyverse)
library(foreign)
files <- dir(getwd(), pattern = "\\.sav$", full.names = FALSE) 
df_list <- vector("list", length(files))
names(df_list) <- files
read_in <- function(df = files) {
  for (fname in df) {
    df_list[[fname]] <- haven::read_sav(fname, encoding = NULL, user_na = FALSE, col_select = NULL,skip = 0, n_max = Inf, .name_repair = "unique") 
  }
    names(df_list) <- gsub(".sav","",names(df_list))
    ff <- df_list
}


df_list <- read_in(files)

list2env(df_list,envir=.GlobalEnv)

pre_df <- as.data.frame(Grad2_Preselection) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

```

# Prepare dataset

## Get dataset

```{r}
files <- dir(getwd(), pattern = "\\.sav$", full.names = FALSE) 
df_list <- vector("list", length(files))
names(df_list) <- files
read_in <- function(df = files) {
  for (fname in df) {
    df_list[[fname]] <- haven::read_sav(fname, encoding = NULL, user_na = FALSE, col_select = NULL,skip = 0, n_max = Inf, .name_repair = "unique") 
  }
    names(df_list) <- gsub(".sav","",names(df_list))
    ff <- df_list
}


df_list <- read_in(files)

list2env(df_list,envir=.GlobalEnv)

pre_df <- as.data.frame(Grad2_Preselection) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

T1_1 <- as.data.frame(Grad2_T1) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

T1_2 <- as.data.frame(Grad2_T1_2) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

T1 <- rbind(T1_1, T1_2)

T2 <- as.data.frame(Grad2_T2) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

T3 <- as.data.frame(Grad2_T3) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

T4 <- as.data.frame(Grad2_T4) %>% 
  dplyr::rename(
    DurationT1 = Duration__in_seconds_
    )

```

## Joint df

```{r}
T1T2 <- left_join(T1, T2, by = c("t1id" = "t2id"))
T1T2T3 <- left_join(T1T2, T3, by = c("t1id" = "t3id"))
T1T2T3T4 <- left_join(T1T2T3, T4, by = c("t1id" = "t4id"))

# exclude all without prolific ID
df <- T1T2T3T4[!(nchar(T1T2T3T4$t1id)!=24),]

# remove duplicate entries
df <- df[!duplicated(df$t1id), ]
```

## Recoding 

```{r}
df <- df %>%
  mutate_at(vars(matches("cplan_1|cplan_5|cplan_6|stress_2|stress_4")),
            ~ (6 - .))

df <- df %>%
  mutate_at(vars(matches("learn_4|vita_5")),
            ~ (8 - .))
```

## Delete irrelevant columns 

```{r}
df_sel <- df %>% dplyr::select(-matches("StartDate|EndDate|Status|IPAddress|Progress|Duration|Finished|Recorded|Response|Recipient|External|Location|Distribution|User|comment|SC0|_TEXT|occf|t1id|t3empse"))
```

## PANA and exhaustion 

```{r}
colnames(df_sel) <- gsub('PANA_10', 'PA_5', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_11', 'Exhaust_1', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_12', 'Exhaust_2', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_13', 'Exhaust_3', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_1', 'PA_1', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_2', 'NA_1', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_3', 'NA_2', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_4', 'PA_2', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_5', 'NA_3', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_6', 'PA_3', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_7', 'NA_4', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_8', 'NA_5', colnames(df_sel))
colnames(df_sel) <- gsub('PANA_9', 'PA_4', colnames(df_sel))
```

## Coping sucscales

```{r}
colnames(df_sel) <- gsub('coping_10', 'copediseng_2', colnames(df_sel))
colnames(df_sel) <- gsub('coping_1', 'copeactive_1', colnames(df_sel))
colnames(df_sel) <- gsub('coping_2', 'copeactive_2', colnames(df_sel))
colnames(df_sel) <- gsub('coping_3', 'copeposref_1', colnames(df_sel))
colnames(df_sel) <- gsub('coping_4', 'copeposref_2', colnames(df_sel))
colnames(df_sel) <- gsub('coping_5', 'copeaccept_1', colnames(df_sel))
colnames(df_sel) <- gsub('coping_6', 'copeaccept_2', colnames(df_sel))
colnames(df_sel) <- gsub('coping_7', 'copeselfdistr_1', colnames(df_sel))
colnames(df_sel) <- gsub('coping_8', 'copeselfdistr_2', colnames(df_sel))
colnames(df_sel) <- gsub('coping_9', 'copediseng_1', colnames(df_sel))
```

## Anticipated emotions

```{r}
colnames(df_sel) <- gsub('antic_1', 'anticneg_1', colnames(df_sel))
colnames(df_sel) <- gsub('antic_2', 'anticneg_2', colnames(df_sel))
colnames(df_sel) <- gsub('antic_3', 'anticpos_1', colnames(df_sel))
colnames(df_sel) <- gsub('antic_4', 'anticpos_2', colnames(df_sel))
```

# Reliabilities

```{r prepare_comp_alph_df}
library(tidyverse)
library(multicon)
library(psych)
library(sjlabelled)

demo_dat <- df_sel %>% dplyr::select(matches("found|start|apply|signf|date|relaf|indu|hrps|whrf|whr|t4coun|t4cedu|t4csear|t4lprof|t4edu|t4grade|t4prevjob|t4couns"))

single_item <- df_sel %>% dplyr::select(matches("sestm_1|sleep|health"))

not_include <- df_sel %>% dplyr::select(matches("change|t4field|t4pdegr"))

comp_dat <- df_sel %>%
  dplyr::select(-matches("T1W|found|start|apply|signf|date|relaf|indu|hrps|whrf|whr|change|t4coun|t4cedu|t4csear|t4lprof|t4edu|t4field|t4grade|t4pdegr|t4prevjob|t4couns|sestm_1|sleep|health", ignore.case = F)) %>% lapply(.,as.numeric) %>% as.data.frame(.)


alph_dat <- comp_dat


comp_split <- comp_dat %>%
  split.default(sub("_.*", "", names(comp_dat))) 

alph_split <- alph_dat %>% 
  split.default(sub("_.*", "", names(alph_dat))) 

comp <- purrr::map(comp_split, ~ multicon::composite(.x, nomiss = 0.8), data = .x)
alph <- purrr::map(alph_split, ~ psych::alpha(.x), data = .x) %>%
  purrr::map(~ .x$total)
options(warn=0)

# add demos and single items 
comp_df <- do.call("cbind", comp) %>%
  cbind(demo_dat, .) %>% cbind(., single_item)

alph_df <- do.call("rbind", alph) %>% round(., 2)


```

``` {r reliabilities, include = T, echo = F}
alph_df %>%
DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 20))

```

# Correlations
```{r corr_table}
library(xtable)
cor <- round(cor(comp_df, use="pairwise.complete.obs"), 2)

corstars <-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower", "none"),
                     result=c("none", "html", "latex")){
    #Compute correlation matrix
    require(Hmisc)
    x <- as.matrix(x)
    correlation_matrix<-rcorr(x, type=method[1])
    R <- correlation_matrix$r # Matrix of correlation coeficients
    p <- correlation_matrix$P # Matrix of p-value 
    
    ## Define notions for significance levels; spacing is important.
    mystars <- ifelse(p < .001, "*** ", ifelse(p < .01, "**  ", ifelse(p < .05, "*   ", "    ")))
    
    ## trunctuate the correlation matrix to two decimal
    R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
    
    ## build a new matrix that includes the correlations with their apropriate stars
    Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
    diag(Rnew) <- paste(diag(R), " ", sep="")
    rownames(Rnew) <- colnames(x)
    colnames(Rnew) <- paste(colnames(x), "", sep="")
    
    ## remove upper triangle of correlation matrix
    if(removeTriangle[1]=="upper"){
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove lower triangle of correlation matrix
    else if(removeTriangle[1]=="lower"){
      Rnew <- as.matrix(Rnew)
      Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    else if(removeTriangle[1]=="none"){
      Rnew <- as.matrix(Rnew)
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove last column and return the correlation matrix
    Rnew <- cbind(Rnew[1:length(Rnew)-1])
    if (result[1]=="none") return(Rnew)
    else{
      if(result[1]=="html") print(xtable(Rnew), type="html")
      else print(xtable(Rnew), type="latex") 
    }
} 
library(kableExtra)

corstar <- data.frame(corstars(comp_df, removeTriangle = "none", result="none"))

corstars_2 <-function(x, method=c("pearson", "spearman"), removeTriangle=c("upper", "lower", "none"),
                     result=c("none", "html", "latex")){
    #Compute correlation matrix
    require(Hmisc)
    x <- as.matrix(x)
    correlation_matrix<-rcorr(x, type=method[1])
    R <- correlation_matrix$r # Matrix of correlation coeficients
    
    ## trunctuate the correlation matrix to two decimal
    R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
    
    ## build a new matrix that includes the correlations with their apropriate stars
    Rnew <- matrix(R, ncol=ncol(x))
    diag(Rnew) <- paste(diag(R), " ", sep="")
    rownames(Rnew) <- colnames(x)
    colnames(Rnew) <- paste(colnames(x), "", sep="")
    
    ## remove upper triangle of correlation matrix
    if(removeTriangle[1]=="upper"){
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove lower triangle of correlation matrix
    else if(removeTriangle[1]=="lower"){
      Rnew <- as.matrix(Rnew)
      Rnew[lower.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
    }
    
    else if(removeTriangle[1]=="none"){
      Rnew <- as.matrix(Rnew)
      Rnew <- as.data.frame(Rnew)
    }
    
    ## remove last column and return the correlation matrix
    Rnew <- cbind(Rnew[1:length(Rnew)-1])
    if (result[1]=="none") return(Rnew)
    else{
      if(result[1]=="html") print(xtable(Rnew), type="html")
      else print(xtable(Rnew), type="latex") 
    }
} 


corstar_select <- data.frame(corstars(comp_df, removeTriangle = "upper", result="none"))

print(xtable(corstar_select, type = "latex"), file = "cor_comp_df.tex")

corstar_select %>%
  DT::datatable(
    extensions = 'Buttons', 
    options = list(dom = 'Bfrtip', 
                   buttons = c('excel', "csv"),
                   pageLength = 35,
                  lengthMenu = c(25, 50, 75, 94)))

```

# LPA

```{r lp, evaluate = FALSE, include = FALSE, echo = TRUE, message = FALSE, warning = FALSE}
library(tidyLPA)
library(mclust)
library(MplusAutomation)
library(mix)
library(kableExtra)
## Selected Scales: t1netw, t1plan, t1infsk, t1caeng, t1cplan
LPA_df = comp_df %>% dplyr::select(t1netw, t1cconf, t1cplan) 

#single imputation
LPA_df_imp = single_imputation(LPA_df, method = "missForest")

# check distribution
# pairs.panels(LPA_df_imp, stars = TRUE)

# remove outliers
md <- mahalanobis(LPA_df_imp, center = colMeans(LPA_df_imp), cov = cov(LPA_df_imp))
alpha <- .001
cutoff <- (qchisq(p = 1 - alpha, df = ncol(LPA_df_imp)))
names_outliers_MH <- which(md > cutoff)
excluded_mh <- names_outliers_MH
data_noout <- LPA_df_imp[-excluded_mh, ]

# estimate profiles
LPA <- LPA_df %>% estimate_profiles(n_profiles = 2:4, models = 1:6, package = "mplus")
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
plot_lpa <- plot_profiles(LPA)

names(comp_df)

## Selected Scales: t1netw, t1plan, t1infsk, t1caeng, t1cplan
LPA_df = comp_df %>% dplyr::select(t1netw, t1plan) 
nrow(LPA_df)

# estimate profiles
LPA <- LPA_df %>% estimate_profiles(n_profiles = 1:9, models = 1:3)
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
plot_lpa <- plot_profiles(LPA, to_center = T)

# Compare BIC
clustering <- LPA_df %>%
  na.omit() %>%
  mutate_all(list(scale))
BIC <- mclustBIC(clustering)
plot(BIC)
summary(BIC)

# Compute ICL
LPA_df_nona <- LPA_df %>%
  na.omit()
ICL <- mclustICL(LPA_df_nona)

# Get LRT
LRT <- mclustBootstrapLRT(LPA_df_nona, modelName = "VVV")

# get data and fit 
data_lpa <- get_data(LPA)
fit_lpa <- get_fit(LPA)


fit_lpa_kable <- knitr::kable(fit_lpa, escape=FALSE, digits = 2, format = "html", booktabs = TRUE, caption = "Fit LPA solutions") %>%
   kable_styling(position = 'left', full_width = F)

fit_lpa_kable

mclustBootstrapLRT(data_noout, modelName = "VEE")

as_image(fit_lpa_kable, width = 18, height = 10, file = "fit_lpa_kable.png", bs_theme = "simplex", self_contained = TRUE,
 extra_dependencies = NULL, latex_header_includes = NULL, keep_tex = FALSE)

ggsave(plot_lpa, filename = "plot_lpa.png",height = 17, width = 25)

names(comp_df)
```

```{r}
library(missForest)
## Selected Scales: t1netw, t1cconf
LPA_df = comp_df %>% dplyr::select(t1netw, t1cconf) %>%
  na.omit() 

# estimate profiles
LPA <- LPA_df %>% estimate_profiles(n_profiles = 1:5, models = 1:3)
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
plot_lpa <- plot_profiles(LPA, to_center = T)

# Compare BIC
clustering <- LPA_df %>%
  na.omit() %>%
  mutate_all(list(scale))
BIC <- mclustBIC(clustering)
plot(BIC)
summary(BIC)

# Compute ICL
LPA_df_nona <- LPA_df %>%
  na.omit()
ICL <- mclustICL(LPA_df_nona)

# Get LRT
LRT <- mclustBootstrapLRT(LPA_df_nona, modelName = "VVV")

# get data and fit 
data_lpa <- get_data(LPA)
fit_lpa <- get_fit(LPA)


fit_lpa_kable <- knitr::kable(fit_lpa, escape=FALSE, digits = 2, format = "html", booktabs = TRUE, caption = "Fit LPA solutions") %>%
   kable_styling(position = 'left', full_width = F)

fit_lpa_kable

```


# Get Mplus data

```{r}
library(MplusAutomation)
names(comp_df)
mplus_dat <- comp_df %>% remove_all_labels(.) 
View(mplus_dat)
prepareMplusData(mplus_dat, "Mplusdata.dat")
```


# LPA employment self-efficacy, worry, fwself

```{r lp, evaluate = FALSE, include = FALSE, echo = TRUE, message = FALSE, warning = FALSE}
library(tidyLPA)
library(mclust)
library(MplusAutomation)
library(mix)
library(kableExtra)
## prepare Mplius
names(comp_df)
LPA_df = comp_df %>% dplyr::select(t1empse, t1wor, t1fwself, t2adapt, t2caeng, t2cplan, t2Exhaust, t2exre, t2infsk, t2netw, t2plan, t2psom, t2stress) 
comp_df$t1empse
prepareMplusData(LPA_df, "man3step.dat")

# LPA
LPA_df = comp_df %>% dplyr::select(t1empse, t1wor, t1fwself)
#single imputation
LPA_df_imp = single_imputation(LPA_df, method = "missForest")

# check distribution
# pairs.panels(LPA_df_imp, stars = TRUE)

# remove outliers
md <- mahalanobis(LPA_df_imp, center = colMeans(LPA_df_imp), cov = cov(LPA_df_imp))
alpha <- .001
cutoff <- (qchisq(p = 1 - alpha, df = ncol(LPA_df_imp)))
names_outliers_MH <- which(md > cutoff)
excluded_mh <- names_outliers_MH
data_noout <- LPA_df_imp[-excluded_mh, ]

# estimate profiles
LPA <- (LPA_df %>% estimate_profiles(n_profiles = 3:5, models = 1:6, package = "mplus"))
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
plot_lpa <- plot_profiles(LPA)

names(comp_df)

compare_solutions(LPA)

# Compare BIC
clustering <- LPA_df_imp %>%
  na.omit() %>%
  mutate_all(list(scale))
BIC <- mclustBIC(clustering)
plot(BIC)
summary(BIC)

# Compute ICL
LPA_df_nona <- LPA_df %>%
  na.omit()
ICL <- mclustICL(LPA_df_nona)

# Get LRT
LRT <- mclustBootstrapLRT(LPA_df_nona, modelName = "VVV")

# get data and fit 
data_lpa <- get_data(LPA)
fit_lpa <- get_fit(LPA)
get_estimates(LPA)
print(LPA)

fit_lpa_kable <- knitr::kable(fit_lpa, escape=FALSE, digits = 2, format = "html", booktabs = TRUE, caption = "Fit LPA solutions") %>%
   kable_styling(position = 'left', full_width = F)

fit_lpa_kable

mclustBootstrapLRT(data_noout, modelName = "VEE")

as_image(fit_lpa_kable, width = 18, height = 10, file = "fit_lpa_kable.png", bs_theme = "simplex", self_contained = TRUE,
 extra_dependencies = NULL, latex_header_includes = NULL, keep_tex = FALSE)

ggsave(plot_lpa, filename = "plot_lpa.png",height = 17, width = 25)

names(comp_df)

comp_df$t1empse
```

```{r}
library(missForest)
## Selected Scales: t1netw, t1cconf
LPA_df = comp_df %>% select(t1netw, t1cconf) %>%
  na.omit() 

# estimate profiles
LPA <- LPA_df %>% estimate_profiles(n_profiles = 1:5, models = 1:3)
compare_lpa <- compare_solutions(LPA, statistics = c("BIC", "AIC", "Entropy"))
plot_lpa <- plot_profiles(LPA, to_center = T)

# Compare BIC
clustering <- LPA_df %>%
  na.omit() %>%
  mutate_all(list(scale))
BIC <- mclustBIC(clustering)
plot(BIC)
summary(BIC)

# Compute ICL
LPA_df_nona <- LPA_df %>%
  na.omit()
ICL <- mclustICL(LPA_df_nona)

# Get LRT
LRT <- mclustBootstrapLRT(LPA_df_nona, modelName = "VVV")

# get data and fit 
library(MplusAutomation)
LPA <- LPA_df_imp %>% estimate_profiles(n_profiles = 5, models = 3, package = "mclust")

idata_lpa <- get_data(LPA)
fit_lpa <- get_fit(LPA)


fit_lpa_kable <- knitr::kable(fit_lpa, escape=FALSE, digits = 2, format = "html", booktabs = TRUE, caption = "Fit LPA solutions") %>%
   kable_styling(position = 'left', full_width = F)

fit_lpa_kable

```





